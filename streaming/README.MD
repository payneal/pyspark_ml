# Spark Streaming 

* is an extension of the core Spark API that enables scalable, high-throughput, fault-tolerant stream processing of live data streams
* data can be ingested from many sources like Kafka, Flume, Kinesis, or TCP sockets, and can be processed using complex algo expressedwith high-level functions like map, reduce, join and window
* Internally, Spark Streaming recieves live input data streams and divides the data into batches which are then processe by the spark engineto generate the finial stream of results in batches

